# ChatAI Microservice

Service de chat basÃ© sur l'IA utilisant Ollama3 pour des conversations intelligentes avec gestion complÃ¨te des utilisateurs et des sessions.

## ğŸš€ FonctionnalitÃ©s

### Core Features
- **Chat Intelligence**: IntÃ©gration avec Ollama3 LLM pour des conversations naturelles
- **Gestion des Conversations**: CrÃ©ation, modification, archivage et recherche de conversations
- **Historique Complet**: Sauvegarde et rÃ©cupÃ©ration de l'historique des messages
- **Authentification JWT**: IntÃ©gration avec le service auth-service pour la sÃ©curitÃ©
- **Rate Limiting**: Protection contre les abus avec limites de requÃªtes configurables
- **Sessions Utilisateur**: Gestion avancÃ©e des sessions avec tracking des tokens et requÃªtes

### Features Techniques
- **API REST** avec documentation Swagger/OpenAPI
- **Validation** automatique des donnÃ©es d'entrÃ©e
- **Gestion d'erreurs** globale avec messages en franÃ§ais
- **Cache intelligent** avec Caffeine pour optimiser les performances
- **Streaming SSE** pour les rÃ©ponses en temps rÃ©el
- **Tests unitaires** complets avec couverture Ã©levÃ©e

## ğŸ—ï¸ Architecture

```
src/
â”œâ”€â”€ main/java/ci/hardwork/chatai/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ models/          # EntitÃ©s JPA (Conversation, Message, UserSession)
â”‚   â”‚   â”œâ”€â”€ repository/      # Repositories Spring Data
â”‚   â”‚   â”œâ”€â”€ service/         # Services mÃ©tier
â”‚   â”‚   â”œâ”€â”€ mapper/          # Mappers MapStruct
â”‚   â”‚   â””â”€â”€ dto/            # Data Transfer Objects
â”‚   â”œâ”€â”€ web/
â”‚   â”‚   â””â”€â”€ controller/     # Controllers REST
â”‚   â”œâ”€â”€ security/           # Configuration JWT et sÃ©curitÃ©
â”‚   â”œâ”€â”€ config/            # Configuration Spring
â”‚   â””â”€â”€ exception/         # Gestion des erreurs
â””â”€â”€ test/                  # Tests unitaires et d'intÃ©gration
```

## ğŸ› ï¸ Technologies

### Backend
- **Java 17** - Langage principal
- **Spring Boot 3.5.4** - Framework principal
- **Spring AI** - IntÃ©gration IA avec Ollama
- **Spring Security** - Authentification et autorisation
- **Spring Data JPA** - Persistance des donnÃ©es
- **PostgreSQL** - Base de donnÃ©es principale
- **MapStruct** - Mapping objet-Ã -objet
- **Caffeine** - Cache en mÃ©moire

### DevOps
- **Docker** & **Docker Compose** - Conteneurisation
- **Maven** - Gestion des dÃ©pendances
- **JUnit 5** & **Mockito** - Tests
- **Swagger/OpenAPI** - Documentation API

## ğŸš€ DÃ©marrage Rapide

### PrÃ©requis
- Java 17+
- Maven 3.6+
- Docker & Docker Compose
- Service auth-service en cours d'exÃ©cution

### Installation avec Docker (RecommandÃ©)

1. **Cloner le projet**
```bash
git clone <repository-url>
cd ChatAI
```

2. **DÃ©marrer avec Docker Compose**
```bash
docker-compose up -d
```

Ceci dÃ©marre:
- ChatAI service sur le port 8081
- PostgreSQL sur le port 5433
- Ollama sur le port 11434

3. **Initialiser Ollama avec le modÃ¨le llama3**
```bash
docker exec -it chatai-ollama ollama pull llama3
```

### Installation Manuelle

1. **Configuration de la base de donnÃ©es**
```sql
CREATE DATABASE chatai_db;
CREATE USER chatai_user WITH PASSWORD 'chatai_password';
GRANT ALL PRIVILEGES ON DATABASE chatai_db TO chatai_user;
```

2. **Configuration des variables d'environnement**
```bash
export SPRING_DATASOURCE_URL=jdbc:postgresql://localhost:5432/chatai_db
export SPRING_DATASOURCE_USERNAME=chatai_user
export SPRING_DATASOURCE_PASSWORD=chatai_password
export APP_AUTH_SERVICE_URL=http://localhost:8080
export APP_AI_OLLAMA_BASE_URL=http://localhost:11434
```

3. **DÃ©marrer l'application**
```bash
mvn spring-boot:run
```

## ğŸ“š API Documentation

L'API est documentÃ©e avec Swagger et accessible Ã :
- **Swagger UI**: http://localhost:8081/swagger-ui.html
- **OpenAPI JSON**: http://localhost:8081/v3/api-docs

### Endpoints Principaux

#### Chat
- `POST /chat/message` - Envoyer un message
- `POST /chat/message/stream` - Conversation en streaming
- `POST /chat/generate-title` - GÃ©nÃ©rer un titre
- `GET /chat/models/{modelName}/check` - VÃ©rifier un modÃ¨le

#### Conversations  
- `GET /conversations` - Lister les conversations
- `POST /conversations` - CrÃ©er une conversation
- `GET /conversations/{id}` - Obtenir une conversation
- `PUT /conversations/{id}` - Mettre Ã  jour une conversation
- `DELETE /conversations/{id}` - Supprimer une conversation
- `GET /conversations/search` - Rechercher des conversations

## ğŸ”§ Configuration

### Variables d'Environnement

| Variable | Description | DÃ©faut |
|----------|-------------|--------|
| `APP_AUTH_SERVICE_URL` | URL du service d'authentification | `http://localhost:8080` |
| `APP_AI_OLLAMA_BASE_URL` | URL de base d'Ollama | `http://localhost:11434` |
| `APP_AI_OLLAMA_MODEL` | ModÃ¨le IA par dÃ©faut | `llama3` |
| `APP_RATE_LIMIT_REQUESTS_PER_MINUTE` | Limite de requÃªtes par minute | `60` |
| `APP_RATE_LIMIT_BURST_CAPACITY` | CapacitÃ© de burst | `10` |

### Configuration Spring (application.yml)

```yaml
spring:
  ai:
    ollama:
      base-url: ${APP_AI_OLLAMA_BASE_URL:http://localhost:11434}
      chat:
        options:
          model: ${APP_AI_OLLAMA_MODEL:llama3}
          temperature: 0.7
          max-tokens: 2000

app:
  auth-service:
    url: ${APP_AUTH_SERVICE_URL:http://localhost:8080}
  rate-limit:
    requests-per-minute: ${APP_RATE_LIMIT_REQUESTS_PER_MINUTE:60}
    burst-capacity: ${APP_RATE_LIMIT_BURST_CAPACITY:10}
```

## ğŸ§ª Tests

### ExÃ©cuter tous les tests
```bash
mvn test
```

### Tests spÃ©cifiques
```bash
mvn test -Dtest=ChatServiceTest
mvn test -Dtest=ConversationServiceTest
```

### Couverture des tests
- **Services**: Tests unitaires complets avec mocks
- **Repositories**: Tests d'intÃ©gration avec base de donnÃ©es embarquÃ©e
- **Controllers**: Tests avec MockMvc

## ğŸ”’ SÃ©curitÃ©

### Authentification
- **JWT Tokens**: Validation via appels REST au service auth-service
- **RÃ´les**: Support des rÃ´les PATIENT, DOCTOR, ADMIN
- **Sessions**: Gestion des sessions utilisateur avec tracking

### Rate Limiting
- **Par minute**: Limite configurable de requÃªtes par utilisateur
- **Burst protection**: Protection contre les pics de trafic
- **Token tracking**: Surveillance de l'utilisation des tokens IA

## ğŸ“Š Monitoring & ObservabilitÃ©

### Health Checks
- `GET /actuator/health` - Status de l'application
- `GET /actuator/info` - Informations sur l'application

### MÃ©triques
- MÃ©triques Micrometer intÃ©grÃ©es
- Monitoring des appels IA
- Tracking des performances

## ğŸ³ Docker

### Build Image
```bash
docker build -t chatai-service .
```

### Variables d'environnement Docker
Voir `docker-compose.yml` pour la configuration complÃ¨te.

## ğŸ“ˆ Performance

### Optimisations
- **Cache Caffeine** pour les titres gÃ©nÃ©rÃ©s et modÃ¨les
- **Connection pooling** pour la base de donnÃ©es
- **Lazy loading** pour les relations JPA
- **Pagination** pour les listes importantes

### Recommandations de Production
- Configurer un reverse proxy (nginx)
- Utiliser une base Redis pour le cache distribuÃ©
- Mettre en place un monitoring avec Prometheus/Grafana
- Configurer des logs centralisÃ©s (ELK Stack)

## ğŸ¤ IntÃ©gration avec d'autres Services

### Auth Service
- Validation des tokens JWT via REST API
- RÃ©cupÃ©ration des informations utilisateur
- Gestion des rÃ´les et permissions

### Ollama
- IntÃ©gration native via Spring AI
- Support de multiple modÃ¨les
- Gestion des erreurs et retry automatique

## ğŸ“ Logs

Les logs sont configurÃ©s en franÃ§ais et incluent:
- Informations de sessions utilisateur
- Tracking des conversations
- MÃ©triques de performance IA
- Erreurs dÃ©taillÃ©es avec contexte

## ğŸ”„ DÃ©veloppement

### Ajouter un nouveau modÃ¨le IA
1. Configurer le modÃ¨le dans Ollama
2. Ajouter la configuration dans `application.yml`
3. Tester via l'endpoint `/chat/models/{modelName}/check`

### DÃ©veloppement local
```bash
# DÃ©marrer uniquement les services externes
docker-compose up -d postgres ollama

# DÃ©marrer l'application en mode dÃ©veloppement
mvn spring-boot:run -Dspring.profiles.active=dev
```

## ğŸ“‹ TODO / AmÃ©liorations Futures

- [ ] Interface WebSocket pour chat temps rÃ©el
- [ ] Support de fichiers joints (images, documents)
- [ ] SystÃ¨me de plugins pour Ã©tendre les capacitÃ©s IA
- [ ] Dashboard administrateur pour monitoring
- [ ] API GraphQL en complÃ©ment de REST
- [ ] Support multi-langues complet

## ğŸ› Troubleshooting

### ProblÃ¨mes courants

**Erreur de connexion Ollama**
```bash
# VÃ©rifier qu'Ollama est dÃ©marrÃ©
curl http://localhost:11434/api/tags

# TÃ©lÃ©charger le modÃ¨le si nÃ©cessaire
docker exec -it chatai-ollama ollama pull llama3
```

**Erreur de base de donnÃ©es**
```bash
# VÃ©rifier la connexion PostgreSQL
docker exec -it chatai-postgres psql -U chatai_user -d chatai_db
```

**Tests qui Ã©chouent**
- S'assurer que les ports ne sont pas occupÃ©s
- VÃ©rifier que Docker est dÃ©marrÃ©
- Nettoyer les donnÃ©es de test : `mvn clean test`

---

## ğŸ† QualitÃ© du Code

- **Architecture**: Clean Architecture avec sÃ©paration des responsabilitÃ©s
- **SOLID**: Principes SOLID respectÃ©s
- **DRY**: Code sans duplication
- **Tests**: Couverture de tests Ã©levÃ©e
- **Documentation**: Code auto-documentÃ© et Javadoc
- **Standards**: Respect des conventions Java/Spring